<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Statistical Reasoning - 2&nbsp; Probability Models: How Do I Get a Sampling Distribution?</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./summary.html" rel="next">
<link href="./01-samplingdistr.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability Models: How Do I Get a Sampling Distribution?</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Statistical Reasoning</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Introduction and Reader’s Guide</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-samplingdistr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Sampling Distribution: How Different Could My Sample Have Been?</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-probability.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability Models: How Do I Get a Sampling Distribution?</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Summary</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul class="collapse">
  <li><a href="#boot-approx" id="toc-boot-approx" class="nav-link active" data-scroll-target="#boot-approx"><span class="toc-section-number">2.1</span>  The Bootstrap Approximation of the Sampling Distribution</a></li>
  <li><a href="#boot-spss" id="toc-boot-spss" class="nav-link" data-scroll-target="#boot-spss"><span class="toc-section-number">2.2</span>  Bootstrapping in SPSS</a></li>
  <li><a href="#exact-approaches-to-the-sampling-distribution" id="toc-exact-approaches-to-the-sampling-distribution" class="nav-link" data-scroll-target="#exact-approaches-to-the-sampling-distribution"><span class="toc-section-number">2.3</span>  Exact Approaches to the Sampling Distribution</a></li>
  <li><a href="#SPSS-exact" id="toc-SPSS-exact" class="nav-link" data-scroll-target="#SPSS-exact"><span class="toc-section-number">2.4</span>  Exact Approaches in SPSS</a></li>
  <li><a href="#theoretical-approximations-of-the-sampling-distribution" id="toc-theoretical-approximations-of-the-sampling-distribution" class="nav-link" data-scroll-target="#theoretical-approximations-of-the-sampling-distribution"><span class="toc-section-number">2.5</span>  Theoretical Approximations of the Sampling Distribution</a></li>
  <li><a href="#spss-and-theoretical-approximation-of-the-sampling-distribution" id="toc-spss-and-theoretical-approximation-of-the-sampling-distribution" class="nav-link" data-scroll-target="#spss-and-theoretical-approximation-of-the-sampling-distribution"><span class="toc-section-number">2.6</span>  SPSS and Theoretical Approximation of the Sampling Distribution</a></li>
  <li><a href="#when-do-we-use-which-approach-to-the-sampling-distribution" id="toc-when-do-we-use-which-approach-to-the-sampling-distribution" class="nav-link" data-scroll-target="#when-do-we-use-which-approach-to-the-sampling-distribution"><span class="toc-section-number">2.7</span>  When Do We Use Which Approach to the Sampling Distribution?</a></li>
  <li><a href="#test-your-understanding" id="toc-test-your-understanding" class="nav-link" data-scroll-target="#test-your-understanding"><span class="toc-section-number">2.8</span>  Test Your Understanding</a></li>
  <li><a href="#take-home-points" id="toc-take-home-points" class="nav-link" data-scroll-target="#take-home-points"><span class="toc-section-number">2.9</span>  Take-Home Points</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="probmodels" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probability Models: How Do I Get a Sampling Distribution?</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<blockquote class="blockquote">
<p>Key concepts: bootstrapping/bootstrap sample, sampling with replacement, exact approach, approximation with a theoretical probability distribution, binomial distribution, (standard) normal distribution, (Student) <em>t</em> distribution, <em>F</em> distribution, chi-squared distribution, condition checks for theoretical probability distributions, sample size, equal population variances, independent samples, dependent/paired samples.</p>
</blockquote>
<p>Watch this micro lecture on probability models for an overview of the chapter.</p>
<div class="cell" data-layout-align="center" data-screenshot.opts="{&quot;delay&quot;:5}">
<iframe src="https://www.youtube.com/embed/zA6_9Mbg8d0" width="640px" height="360px" data-external="1">
</iframe>
</div>
<section id="summary" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="summary">Summary</h3>
<div class="cell" type="rmdimportant">

<div class="rmdimportant">
How do we get a sampling distribution without drawing many samples ourselves?
</div>
</div>
<p>In the previous chapter, we drew a large number of samples from a population to obtain the sampling distribution of a sample statistic, for instance, the proportion of yellow candies or average candy weight in the sample. The procedure is quite simple: Draw a sample, calculate the desired sample statistic, add the sample statistic value to the sampling distribution, and repeat this thousands of times.</p>
<p>Although this procedure is simple, it is not practical. In a research project, we would have to draw thousands of samples and administer a survey to each sample or collect data on the sample in some other way. This requires too much time and money to be of any practical value. So how do we create a sampling distribution, if we only collect data for a single sample? This chapter presents three ways of doing this: bootstrapping, exact approaches, and theoretical approximations.</p>
<p>After studying this chapter, you should know the limitations of the three methods of creating a sampling distribution, when to use which method, and how to check the conditions for using a method.</p>
</section>
<section id="boot-approx" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="boot-approx"><span class="header-section-number">2.1</span> The Bootstrap Approximation of the Sampling Distribution</h2>
<p>The first way to obtain a sampling distribution is still based on the idea of drawing a large number of samples. However, we only draw one sample from the population for which we collect data. As a next step, we draw a large number of samples from our initial sample. The samples drawn in the second step are called <em>bootstrap samples</em>. The technique was developed by Bradley Efron <span class="citation" data-cites="RefWorks:3956 RefWorks:3957">(<a href="references.html#ref-RefWorks:3956" role="doc-biblioref"><strong>RefWorks:3956?</strong></a>; <a href="references.html#ref-RefWorks:3957" role="doc-biblioref"><strong>RefWorks:3957?</strong></a>)</span>. For each bootstrap sample, we calculate the sample statistic of interest and we collect these as our sampling distribution. We usually want about 5,000 bootstrap samples for our sampling distribution.</p>
<div class="cell" data-layout-align="center" data-screenshot.opts="{&quot;delay&quot;:5}">
<iframe src="http://82.196.4.233:3838/apps/bootstrapping/?showcase=0" width="775px" height="462px" data-external="1">
</iframe>
</div>
<p>In Figure @ref(fig:bootstrapping), an initial sample (left panel) has been drawn from a population containing five candy colours in equal proportions.</p>
<a name="question2.1.1"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol type="1">
<li>How large is a bootstrap sample in Figure @ref(fig:bootstrapping)? Use the <em>Bootstrap one sample</em> button. <a href="#answer2.1.1"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.1.2"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="2" type="1">
<li>What element in Figure @ref(fig:bootstrapping) represents the true sampling distribution in this example? If in doubt, see Figure @ref(fig:probability-distribution). <a href="#answer2.1.2"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.1.3"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="3" type="1">
<li>Does the bootstrap sampling distribution resemble the true sampling distribution? Use the “Bootstrap 5,000 samples” button and justify your answer. <a href="#answer2.1.3"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.1.4"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="4" type="1">
<li>Draw a new initial sample. This sample is probably not representative of the distribution of candy colour in the population. What happens to the bootstrap samples and the bootstrap sampling distribution? <a href="#answer2.1.4"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<div class="cell" type="rmdmunchhausen">

<div class="rmdmunchhausen">
<p>The <em>bootstrap</em> concept refers to the story in which Baron von Münchhausen saves himself by pulling himself and his horse by his bootstraps (or hair) out of a swamp. In a similar miraculous way, bootstrap samples resemble the sampling distribution even though they are drawn from a sample instead of the population. This miracle requires some explanation and it does not work always, as we will discuss in the remainder of this section.</p>
<a href="https://commons.wikimedia.org/wiki/File:M%C3%BCnchhausen-Sumpf-Hosemann.png">Picture: Baron von Münchhausen pulls himself and his horse out of a swamp. Theodor Hosemann (1807-1875), public domain, via Wikimedia Commons</a>
</div>
</div>
<section id="sampling-with-and-without-replacement" class="level3">
<h3 class="anchored" data-anchor-id="sampling-with-and-without-replacement">Sampling with and without replacement</h3>
<p>As we will see in Chapter @ref(param-estim), for example Section @ref(precisionsesamplesize), the size of a sample is very important to the shape of the sampling distribution. The sampling distribution of samples with twenty-five cases can be very different from the sampling distribution of samples with fifty cases. To construct a sampling distribution from bootstrap samples, the bootstrap samples must be exactly as large as the original sample.</p>
<p>How can we draw many different bootstrap samples from the original sample if each bootstrap sample must contain the same number of cases as the original sample?</p>
<div class="cell" data-layout-align="center" data-screenshot.opts="{&quot;delay&quot;:5}">
<iframe src="http://82.196.4.233:3838/apps/bootstrapping-replacement/?showcase=0" width="775px" height="448px" data-external="1">
</iframe>
</div>
<a name="question2.1.5"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="5" type="1">
<li>What are the differences between sampling with and without replacement (Figure @ref(fig:replacement))? Press the buttons <em>Draw Without Replacement</em> and <em>Draw With Replacement</em> once or several times to see the differences. <a href="#answer2.1.5"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<p>If we allow every case in the original sample to be sampled only once, each bootstrap sample contains all cases of the original sample, so it is an exact copy of the original sample. Thus, we cannot create different bootstrap samples.</p>
<p>By the way, we often use the type of sampling described above, which is called <em>sampling without replacement</em>. If a person is (randomly) chosen for our sample, we do not put this person back into the population so she or he can be chosen again. We want our respondents to fill out our questionnaire only once or participate in our experiment only once.</p>
<p>If we do allow the same person to be chosen more than once, we sample <em>with replacement</em>. The same person can occur more than once in a sample. Bootstrap samples are sampled with replacement from the original sample, so one bootstrap sample may differ from another. Some cases in the original sample may not be sampled for a bootstrap sample while other cases are sampled several times. You probably have noticed this in Figure @ref(fig:replacement). Sampling with replacement allows us to obtain different bootstrap samples from the original sample, and still have bootstrap samples of the same size as the original sample.</p>
<p>In conclusion, we sample bootstrap samples in a different way (with replacement) than participants for our research (without replacement).</p>
</section>
<section id="limitations-to-bootstrapping" class="level3">
<h3 class="anchored" data-anchor-id="limitations-to-bootstrapping">Limitations to bootstrapping</h3>
<p>Does the bootstrapped sampling distribution always reflect the true sampling distribution?</p>
<div class="cell" data-layout-align="center" data-screenshot.opts="{&quot;delay&quot;:5}">
<iframe src="http://82.196.4.233:3838/apps/bootstrap-lim/?showcase=0" width="420px" height="560px" data-external="1">
</iframe>
</div>
<a name="question2.1.6"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="6" type="1">
<li>When does the bootstrap sampling distribution (yellow histogram) reflect the true sampling distribution (grey histogram) better: at small or large sample sizes? Play with sample size in Figure @ref(fig:bootstrap-lim) to check your answer. <a href="#answer2.1.6"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.1.7"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="7" type="1">
<li>How does sample size relate to representativeness of the sample in terms of the proportion of yellow candies? Note that twenty per cent of the candies in the population are yellow. <a href="#answer2.1.7"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.1.8"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="8" type="1">
<li>If you use a very small sample size, it may happen that there is no yellow histogram in the bottom graph. Why is that? <a href="#answer2.1.8"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<p>We can create a sampling distribution by sampling from our original sample with replacement. It is hardly a miracle that we obtain different samples with different sample statistics if we sample with replacement. Much more miraculous, however, is that this bootstrap distribution resembles the true sampling distribution that we would get if we draw lots of samples directly from the population.</p>
<p>Does this miracle always happen? No.&nbsp;The original sample that we have drawn from the population must be more or less representative of the population. The variables of interest in the sample should be distributed more or less the same as in the population. If this is not the case, the sampling distribution may give a distorted view of the true sampling distribution. This is the main limitation to the bootstrap approach to sampling distributions.</p>
<p>A sample is more likely to be representative of the population if the sample is drawn in a truly random fashion and if the sample is large. But we can never be sure. There always is a chance that we have drawn a sample that does not reflect the population well.</p>
</section>
<section id="any-sample-statistic-can-be-bootstrapped" class="level3">
<h3 class="anchored" data-anchor-id="any-sample-statistic-can-be-bootstrapped">Any sample statistic can be bootstrapped</h3>
<p>The big advantage of the bootstrap approach (<em>bootstrapping</em>) is that we can get a sampling distribution for any sample statistic that we are interested in. Every statistic that we can calculate for our original sample can also be calculated for each bootstrap sample. The sampling distribution is just the collection of the sample statistics calculated for all bootstrap samples.</p>
<p>Bootstrapping is more or less the only way to get a sampling distribution for the sample median, for example, the median weight of candies in a sample bag. We may create sampling distributions for the wildest and weirdest sample statistics, for instance the difference between sample mean and sample median squared. I would not know why you would be interested in the squared difference of sample mean and median, but there are very interesting statistics that we can only get at through bootstrapping. A case in point is the strength of an indirect effect in a mediation model (Chapter @ref(mediation)).</p>
</section>
<section id="answers" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="answers">Answers</h3>
<a name="answer2.1.1"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 1.</p>
<ul>
<li>A bootstrap sample must be just as large as the initial sample. In this example, the initial sample contains twenty-five candies, so the bootstrap sample must also contain twenty-five candies.</li>
<li>As we will find out later, the size of a sample is very important to the sampling distribution, so we must draw bootstrap samples with exactly the same number of observations as the initial sample. <a href="#question2.1.1"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.1.2"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 2.</p>
<ul>
<li>The sampling distribution of a sample proportion is an exact distribution (named binomial distribution): the probabilities of every number or proportion of yellow candies in the sample can be calculated. The results are displayed as a grey histogram at the right of the figure. <a href="#question2.1.2"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.1.3"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 3.</p>
<ul>
<li>The proportion of yellow candies in the (first) initial sample is .2, that is, five out of twenty-five candies in the sample are yellow.</li>
<li>The initial sample is representative of the population with respect to candy colour, because the proportion of yellow candies in the population is also .2.</li>
<li>As a result, the bootstrapped sampling distribution (yellow histogram) is very similar to the true (exact) sampling distribution (grey histogram). <a href="#question2.1.3"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.1.4"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 4.</p>
<ul>
<li>If the proportion of yellow candies in the original sample is close to .2, that is, five out of twenty-five candies in the sample are yellow, the bootstrapped sampling distribution (yellow histogram) is very similar to the true (exact) sampling distribution (grey histogram).</li>
<li>If there are considerably less or more than five yellow candies in the sample, however, the bootstrapped sampling distribution is quite different from the true sampling distribution. Conclusions based on the bootstrapped sampling distribution will be wrong. Especially the mean (horizontal location) of the bootstrapped sampling distribution is different. The shape of the distribution may still be nearly the same.</li>
<li>Note that the true sampling distribution, represented by the grey histogram, remains the same because the proportion of yellow candies in the population remains the same, namely 20 per cent. <a href="#question2.1.4"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.1.5"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 5.</p>
<ul>
<li>If we draw a sample without replacement from our initial sample of the same size as the initial sample, the new sample must contain all observations from the initial sample. As a result, the new sample is identical to the initial sample. All samples that we draw are identical. This does not provide an interesting sampling distribution.</li>
<li>Drawing with replacement, an observation can be drawn more than once. As a result, the same candy number may appear more than once in the new sample. Otherwise, we could never have more candies of a particular color in the bootstrapped sample than in the original sample (five candies of each color). Each new sample drawn with replacement from the original sample can be different, so the proportion of yellow candies varies across these bootstrap samples. We can create a meaningful sampling distribution from these varying proportions of yellow candies. <a href="#question2.1.5"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.1.6"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 6.</p>
<ul>
<li>If you change sample size repeatedly between 15 and 45, you will see that the bootstrapped sampling distribution (yellow histogram) jumps around the true sampling distribution (grey histogram).</li>
<li>For relatively small sample sizes, the bootstrapped sampling distribution is often quite different from the true sampling distribution.</li>
<li>At larger sample sizes, say between 120 and 150, the bootstrapped sampling distribution overlaps the true sampling distribution much more frequently. So for larger samples, we can trust the bootstrapped sampling distribution more. But even then, it can sometimes be quite off the mark. <a href="#question2.1.6"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.1.7"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 7.</p>
<ul>
<li>The proportion of yellow candies in larger samples is more often close to the proportion in the population: 0.2. This is the reason that the bootstrapped sampling distribution resembles the true sampling distribution more often for a larger sample. <a href="#question2.1.7"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.1.8"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 8.</p>
<ul>
<li>If we draw an initial sample without any yellow candies, none of the bootstrap samples can include yellow candies. As a result, the count of samples with yellow candies is always zero.</li>
<li>The smaller the initial sample, the greater the chance of having a sample without yellow candies. <a href="#question2.1.8"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

</section>
</section>
<section id="boot-spss" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="boot-spss"><span class="header-section-number">2.2</span> Bootstrapping in SPSS</h2>
<section id="instructions" class="level3">
<h3 class="anchored" data-anchor-id="instructions">Instructions</h3>
<div class="cell" data-layout-align="center" data-screenshot.opts="{&quot;delay&quot;:5}">
<iframe src="https://www.youtube.com/embed/-6nQsBK4-E8" width="640px" height="360px" data-external="1">
</iframe>
</div>
<div class="cell" data-layout-align="center" data-screenshot.opts="{&quot;delay&quot;:5}">
<iframe src="https://www.youtube.com/embed/6E2LgeMtkL4" width="640px" height="360px" data-external="1">
</iframe>
</div>
<p>In principle, any sample statistic can be bootstrapped. SPSS, however, does not bootstrap sample statistics that we had better not use because they give bad (biased) results. For example, SPSS does not bootstrap the minimum value, maximum value or the range between minimum and maximum value of a variable.</p>
<p>SPSS reports bootstrapping results as confidence intervals. We will discuss confidence intervals in detail in the next chapter.</p>
</section>
<section id="exercises" class="level3">
<h3 class="anchored" data-anchor-id="exercises">Exercises</h3>
<a name="question2.2.1"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol type="1">
<li>Download the data set <a href="http://82.196.4.233:3838/data/candies.sav">candies.sav</a> and use SPSS to bootstrap the <em>t</em> test on average weight of yellow and red candies (the example above). The test is available in the <em>Analyze&gt;Compare Means</em> menu. <a href="#answer2.2.1"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.2.2"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="2" type="1">
<li>Use the same data set to bootstrap the median of candy weight. Remember that measures of central tendency can be obtained with the <em>Frequencies&gt;Statistics</em> command in the <em>Analyze&gt;Descriptive Statistics</em> menu.</li>
</ol>
Tip: Speed up bootstrapping in SPSS by deselecting the option <em>Display frequency tables</em>. <a href="#answer2.2.2"><img src="icons/2answer.png" width="115px" align="right"></a>
</div>
<p>:::</p>
</section>
<section id="answers-1" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="answers-1">Answers</h3>
<a name="answer2.2.1"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Exercise 1.</p>
<p>SPSS syntax:</p>
<p>* Exercise 1: Bootstrap different averages.<br>
* Check data.<br>
FREQUENCIES VARIABLES=colour weight<br>
/ORDER=ANALYSIS.<br>
* Execute independent-samples t test with bootstrap.<br>
BOOTSTRAP<br>
/SAMPLING METHOD=SIMPLE<br>
/VARIABLES TARGET=weight INPUT=colour<br>
/CRITERIA CILEVEL=95 CITYPE=BCA NSAMPLES=5000<br>
/MISSING USERMISSING=EXCLUDE.<br>
T-TEST GROUPS=colour(4 5)<br>
/MISSING=ANALYSIS<br>
/VARIABLES=weight<br>
/CRITERIA=CI(.95).</p>
<p>Check data:</p>
<p>There are no impossible values on the two variables.</p>
<p>Interpret the results:</p>
<p>The table “Bootstrap for Independent Samples Test” contains the results that we are interested in.</p>
<p>Levene’s test on homogeneity of variances is not statistically significant, so we may assume that the population variances of red and yellow candy weight are equal. So we interpret the top row in table “Bootstrap for Independent Samples Test”.</p>
<p>The mean difference between red and yellow candy weight is 0.05 grams. In our sample, red candies are just a little heavier than yellow candies.</p>
<p>The bootstrapped 95% confidence interval for this difference is -0.11 to 0.21. With 95% confidence, we can say that red candies can be on average 0.11 grams lighter than yellow candies or up to 0.21 grams heavier. We cannot tell which of the two are heavier in the population with sufficient confidence.</p>
Note that your results can be slightly different because bootstrapping creates random samples. <a href="#question2.2.1"><img src="icons/2question.png" width="161px" align="right"></a>
</div>
<p>:::</p>
<a name="answer2.2.2"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Exercise 2.</p>
<p>SPSS syntax:</p>
<p>* Exercise 2: Bootstrap on median candy weight.<br>
* Check data.<br>
FREQUENCIES VARIABLES=weight<br>
/ORDER=ANALYSIS.<br>
* Bootstrap the median.<br>
BOOTSTRAP<br>
/SAMPLING METHOD=SIMPLE<br>
/VARIABLES INPUT=weight<br>
/CRITERIA CILEVEL=95 CITYPE=BCA NSAMPLES=5000<br>
/MISSING USERMISSING=EXCLUDE.<br>
FREQUENCIES VARIABLES=weight<br>
/FORMAT=NOTABLE<br>
/STATISTICS=MEDIAN<br>
/ORDER=ANALYSIS.</p>
<p>Check data:</p>
<p>There are no impossible values on the weight variable.</p>
<p>Interpret the results:</p>
Median candy weight in the sample is 2.81 grams. With 95% confidence, we expect median candy weight to be between 2.78 and 2.92 grams in the population of all candies.<br>
The 95% interval borders can be slightly different because bootstrapping takes random samples. <a href="#question2.2.2"><img src="icons/2question.png" width="161px" align="right"></a>
</div>
<p>:::</p>
</section>
</section>
<section id="exact-approaches-to-the-sampling-distribution" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="exact-approaches-to-the-sampling-distribution"><span class="header-section-number">2.3</span> Exact Approaches to the Sampling Distribution</h2>
<p>A second approach to constructing a sampling distribution has implicitly been demonstrated in the preceding section on bootstrapping (Section @ref(boot-approx)) and the section on probability distributions (Section @ref(probdistribution)). In these sections, we calculated the true sampling distribution of the proportion of yellow candies in a sample from the probabilities of the colours. If we know or think we know the proportion of yellow candies in the population, we can exactly calculate the probability that a sample of ten candies includes one, two, three, or ten yellow candies. See the section on discrete random variables for details (Section @ref(discreterandomvariable)).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">

<table class="table" style="font-size: 12px; width: auto !important; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
Number of heads for a toss of three coins.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Outcome
</th>
<th style="text-align:left;">
Combination
</th>
<th style="text-align:left;">
Probability: Combination
</th>
<th style="text-align:right;">
Probability: Outcome
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;">
0
</td>
<td style="text-align:left;color: black !important;background-color: white !important;">
tail-tail-tail
</td>
<td style="text-align:left;color: black !important;background-color: white !important;">
1/2 * 1/2 * 1/2 = 1/8 = .125
</td>
<td style="text-align:right;color: black !important;background-color: white !important;">
1/8 = .125
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: #EEEEEE !important;">
1
</td>
<td style="text-align:left;color: black !important;background-color: #EEEEEE !important;">
tail-tail-head
</td>
<td style="text-align:left;color: black !important;background-color: #EEEEEE !important;">
1/2 * 1/2 * 1/2 = 1/8 = .125
</td>
<td style="text-align:right;color: black !important;background-color: #EEEEEE !important;">
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: #EEEEEE !important;">
1
</td>
<td style="text-align:left;color: black !important;background-color: #EEEEEE !important;">
head-tail-tail
</td>
<td style="text-align:left;color: black !important;background-color: #EEEEEE !important;">
1/2 * 1/2 * 1/2 = 1/8 = .125
</td>
<td style="text-align:right;color: black !important;background-color: #EEEEEE !important;">
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: #EEEEEE !important;">
1
</td>
<td style="text-align:left;color: black !important;background-color: #EEEEEE !important;">
tail-head-tail
</td>
<td style="text-align:left;color: black !important;background-color: #EEEEEE !important;">
1/2 * 1/2 * 1/2 = 1/8 = .125
</td>
<td style="text-align:right;color: black !important;background-color: #EEEEEE !important;">
3/8 = .375
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;">
2
</td>
<td style="text-align:left;color: black !important;background-color: white !important;">
head-head-tail
</td>
<td style="text-align:left;color: black !important;background-color: white !important;">
1/2 * 1/2 * 1/2 = 1/8 = .125
</td>
<td style="text-align:right;color: black !important;background-color: white !important;">
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;">
2
</td>
<td style="text-align:left;color: black !important;background-color: white !important;">
head-tail-head
</td>
<td style="text-align:left;color: black !important;background-color: white !important;">
1/2 * 1/2 * 1/2 = 1/8 = .125
</td>
<td style="text-align:right;color: black !important;background-color: white !important;">
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;">
2
</td>
<td style="text-align:left;color: black !important;background-color: white !important;">
tail-head-head
</td>
<td style="text-align:left;color: black !important;background-color: white !important;">
1/2 * 1/2 * 1/2 = 1/8 = .125
</td>
<td style="text-align:right;color: black !important;background-color: white !important;">
3/8 = .375
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: #EEEEEE !important;">
3
</td>
<td style="text-align:left;color: black !important;background-color: #EEEEEE !important;">
head-head-head
</td>
<td style="text-align:left;color: black !important;background-color: #EEEEEE !important;">
1/2 * 1/2 * 1/2 = 1/8 = .125
</td>
<td style="text-align:right;color: black !important;background-color: #EEEEEE !important;">
1/8 = .125
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:left;">
8
</td>
<td style="text-align:left;">
</td>
<td style="text-align:right;">
1.000
</td>
</tr>
</tbody>

</table>
<p>How does an exact aproach to the sampling distribution work?</p>
</div>
</div>
<a name="question2.3.1"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol type="1">
<li>Explain the meaning of the entries in the column <strong>Combination</strong> and how they relate to the entries in the <strong>Outcome</strong> column. <a href="#answer2.3.1"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.3.2"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="2" type="1">
<li>Explain how the combinations relate to the probabilities. <a href="#answer2.3.2"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<p>The calculated probabilities of all possible sample statistic outcomes give us an exact approach to the sampling distribution. Note that I use the word <em>approach</em> instead of <em>approximation</em> here because the obtained sampling distribution is no longer an approximation, that is, more or less similar to the true sampling distribution. No, it is the true sampling distribution itself.</p>
<section id="exact-approaches-for-categorical-data" class="level3">
<h3 class="anchored" data-anchor-id="exact-approaches-for-categorical-data">Exact approaches for categorical data</h3>
<p>An exact approach lists and counts all possible combinations. This can only be done if we work with discrete or categorical variables. For an unlimited number of categories, we cannot list all possible combinations.</p>
<p>A proportion is based on frequencies and frequencies are discrete (integer values), so we can use an exact approach to create a sampling distribution for one proportion such as the proportion of yellow candies in the example above. The exact approach uses the binomial probability formula to calculate probabilities. Consult the internet if you want to know this formula; we are not going to use it here.</p>
<p>Exact approaches are also available for the association between two categorical (nominal or ordinal) variables in a contingency table: Do some combinations of values for the two variables occur relatively frequently? For example, are yellow candies more often sticky than red candies? If candies are either sticky or not sticky and they have one out of a limited set of colours, we have two categorical variables. We can create an exact probability distribution for the combination of colour and stickiness. The <em>Fisher-exact test</em> is an example of an exact approach to the sampling distribution of the association between two categorical variables.</p>
</section>
<section id="computer-intensive" class="level3">
<h3 class="anchored" data-anchor-id="computer-intensive">Computer-intensive</h3>
<p>The exact approach can be applied to discrete variables because they have a limited number of values. Discrete variables are usually measured at the nominal or ordinal level. If the number of categories becomes large, a lot of computing time can be needed to calculate the probabilities of all possible sample statistic outcomes. Exact approaches are said to be <em>computer-intensive</em>.</p>
<p>It is usually wise to set a limit to the time you allow your computer to work on an exact sampling distribution because otherwise the problem may keep your computer occupied for hours or days.</p>
</section>
<section id="answers-2" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="answers-2">Answers</h3>
<a name="answer2.3.1"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 1.</p>
<ul>
<li>The column “Combination” lists all posible outcomes if we toss three coins.</li>
<li>The sample statistic is the number of heads in a throw of three coins, which is reported in the “Outcome” column. It simply counts the number of heads that appear in the combination.</li>
<li>This number can range from zero to three. This is the sampling space. <a href="#question2.3.1"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.3.2"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 2.</p>
<ul>
<li>There are eight combinations. If the coins are fair, each combination has the same probability of appearing, namely 1/8 = .125. We sum the probabilities for all combinations that have the same outcome, namely the same number of heads.</li>
<li>Thus we arrive at the probability of having no heads in a throw (p = .125), one head (p = .375), and so on. <a href="#question2.3.2"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

</section>
</section>
<section id="SPSS-exact" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="SPSS-exact"><span class="header-section-number">2.4</span> Exact Approaches in SPSS</h2>
<section id="instructions-1" class="level3">
<h3 class="anchored" data-anchor-id="instructions-1">Instructions</h3>
<div class="cell" data-layout-align="center" data-screenshot.opts="{&quot;delay&quot;:5}">
<iframe src="https://www.youtube.com/embed/SrfZeLvsHwg" width="640px" height="360px" data-external="1">
</iframe>
</div>
<div class="cell" data-layout-align="center" data-screenshot.opts="{&quot;delay&quot;:5}">
<iframe src="https://www.youtube.com/embed/PlT28wfc6K4" width="640px" height="360px" data-external="1">
</iframe>
</div>
</section>
<section id="exercises-1" class="level3">
<h3 class="anchored" data-anchor-id="exercises-1">Exercises</h3>
<a name="question2.4.1"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol type="1">
<li>Download the data set <a href="http://82.196.4.233:3838/data/candies.sav">candies.sav</a> and use SPSS to apply a Fisher-exact test to the association between candy colour and candy stickiness. <a href="#answer2.4.1"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.4.2"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="2" type="1">
<li>With the same data, apply a Fisher-exact test to the association between candy colour and candy spottiness. <a href="#answer2.4.2"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

</section>
<section id="answers-3" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="answers-3">Answers</h3>
<a name="answer2.4.1"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Exercise 1.</p>
<p>SPSS syntax:</p>
<p>* Exact test on the relation between candy colour<br>
* and candy stickiness.<br>
CROSSTABS<br>
/TABLES=colour BY sticky<br>
/FORMAT=AVALUE TABLES<br>
/STATISTICS=CHISQ PHI<br>
/CELLS=COUNT COLUMN<br>
/COUNT ROUND CELL<br>
/METHOD=EXACT TIMER(5).</p>
<p>Check data:</p>
<p>The contingency table does not show any impossible values for the two categorical variables.</p>
<p>Interpret the results:</p>
There is a strong association (Cramer’s V = .52) between candy colour and candy stickiness, which is statistically significant, <em>p</em> = .010 (exact). If we look at the percentages in the contingency table, we see that yellow and red candies are less often sticky than blue, green, and orange candies. <a href="#question2.4.1"><img src="icons/2question.png" width="161px" align="right"></a>
</div>
<p>:::</p>
<a name="answer2.4.2"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Exercise 2.</p>
<p>SPSS syntax:</p>
<p>* Exact test on the relation between candy colour<br>
* and candy spottiness.<br>
CROSSTABS<br>
/TABLES=colour BY spotted<br>
/FORMAT=AVALUE TABLES<br>
/STATISTICS=CHISQ PHI<br>
/CELLS=COUNT COLUMN<br>
/COUNT ROUND CELL<br>
/METHOD=EXACT TIMER(5).</p>
<p>Check data:</p>
<p>The contingency table does not show any impossible values for the two categorical variables.</p>
<p>Interpret the results:</p>
There is a weak association (Cramer’s V = .27) between candy colour and candy spottiness, which is not statistically significant, <em>p</em> = .480 (exact) or (using chi-square) <em>p</em> = .555.<br>
Candy colour may be relevant to having spots (weak association) but we are unsure (not statistically significant). <a href="#question2.4.2"><img src="icons/2question.png" width="161px" align="right"></a>
</div>
<p>:::</p>
</section>
</section>
<section id="theoretical-approximations-of-the-sampling-distribution" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="theoretical-approximations-of-the-sampling-distribution"><span class="header-section-number">2.5</span> Theoretical Approximations of the Sampling Distribution</h2>
<p>Because bootstrapping and exact approaches to the sampling distribution require quite a lot of computing power, these methods were not practical in the not so very distant pre-computer age. In those days, mathematicians and statisticians discovered that many sampling distributions look a lot like known mathematical functions. For example, the sampling distribution of the sample mean can be quite similar to the well-known bell-shape of the <em>normal distribution</em> or the closely related <em>(Student) t distribution</em>. The mathematical functions are called <em>theoretical probability distributions</em>. Most statistical tests use a theoretical probability distribution as approximation of the sampling distribution.</p>
<div class="cell" data-layout-align="center" data-screenshot.opts="{&quot;delay&quot;:5}">
<iframe src="http://82.196.4.233:3838/apps/normal-approximation/?showcase=0" width="420px" height="300px" data-external="1">
</iframe>
</div>
<a name="question2.5.1"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol type="1">
<li>Figure @ref(fig:normal-approximation) displays a simulated sampling distribution of sample means and the normal approximation of this distribution (curve). Check if the normal curve is a good approximation of the sampling distribution. <a href="#answer2.5.1"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.5.2"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="2" type="1">
<li>While checking the distribution, pay special attention to the tails because these are used for significance tests (see Chapter @ref(hypothesis)). The red and green bars represent the 2.5 per cent samples with the lowest or highest average weights. The vertical lines mark the outer 2.5 per cent according to the normal distribution. Do the tail borders of the sampling distribution and normal distribution match? <a href="#answer2.5.2"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.5.3"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="3" type="1">
<li>Generate some new sampling distributions to see if the normal function always yields a good approximation. Does the bell-shaped curve fit the histogram? <a href="#answer2.5.3"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<p>The normal distribution is a mathematical function linking continuous scores, e.g., a sample statistic such as the average weight in the sample, to right-hand and left-hand probabilities, that is, to the probability of finding at least, or at most, this score. Such a function is called a <em>probability density function</em> (Section @ref(cont-random-var)).</p>
<p>We like to use a theoretical probability distribution as an approximation of the sampling distribution because it is convenient. A computer can calculate probabilities from the mathematical function very quickly. We also like theoretical probability distributions because they usually offer plausible arguments about chance and probabilities.</p>
<section id="reasons-for-a-bell-shaped-probability-distribution" class="level3">
<h3 class="anchored" data-anchor-id="reasons-for-a-bell-shaped-probability-distribution">Reasons for a bell-shaped probability distribution</h3>
<p>The bell shape of the normal distribution makes sense. Our sample of candies is just as likely to be too heavy, as it is too light, so the sampling distribution of the sample mean should be symmetrical. A normal distribution is symmetrical.</p>
<p>In addition, it is more likely that our sample bag has an average weight that is near the true average candy weight in the population than an average weight that is much larger or much smaller than the true average. Bags with on average extremely heavy or extremely light candies may occur, but they are extremely rare (we are very lucky or very unlucky). From these intuitions we would expect a bell shape for the sampling distribution.</p>
<p>From this argumentation, we conclude that the normal distribution is a reasonable model for the probability distribution of sample means. Actually, it has been proven that the normal distribution exactly represents the sampling distribution in particular cases, for instance the sampling distribution of the mean of a very large sample.</p>
</section>
<section id="cond-probdistr" class="level3">
<h3 class="anchored" data-anchor-id="cond-probdistr">Conditions for the use of theoretical probability distributions</h3>
<p>Theoretical probability distributions, then, are plausible models for sampling distributions. They are known or likely to have the same shape as the true sampling distributions under particular circumstances or conditions.</p>
<p>If we use a theoretical probability distribution, we must assume that the conditions for its use are met. We have to check the conditions and decide whether they are close enough to the ideal conditions. <em>Close enough</em> is of course a matter of judgement. In practice, rules of thumb have been developed to decide if the theoretical probability distribution can be used.</p>
<p>Figure @ref(fig:normal-approx-proportion) shows an example in which the normal distribution is a good approximation for the sampling distribution of a proportion in some situations, but not in all situations.</p>
<div class="cell" data-layout-align="center" data-screenshot.opts="{&quot;delay&quot;:5}">
<iframe src="http://82.196.4.233:3838/apps/normal-approx-proportion/?showcase=0" width="775px" height="305px" data-external="1">
</iframe>
</div>
<a name="question2.5.4"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="4" type="1">
<li>How does sample size affect the shape of the sampling distribution? See what happens if you change sample size in the interactive content. <a href="#answer2.5.4"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.5.5"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="5" type="1">
<li>How does the population proportion affect the shape of the sampling distribution? See what happens if you change the population proportion in the interactive content. <a href="#answer2.5.5"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<p>Do theoretical probability distributions fit the true sampling distribution? As you may have noticed while playing with Figure @ref(fig:normal-approx-proportion), this is not always the case. In general, theoretical probability distributions fit sampling distributions better if the sample is larger. In addition, the population value may be relevant to the fit of the theoretical probability distribution. The sampling distribution of a sample proportion is more symmetrical, like the normal distribution, if the proportion in the population is closer to .5.</p>
<p>This illustrates that we often have several conditions for a theoretical probability distribution to fit the sampling distribution. We should evaluate all of them at the same time. In the example of proportions, a large sample is less important if the true proportion is closer to .5 but it is more important for true proportions that are more distant from .5.</p>
<p>The rule of thumb for using the normal distribution as the sampling distribution of a sample proportion combines the two aspects by multiplying them and requiring the resulting product to be larger than five. If the probability of drawing a yellow candy is .2 and our sample size is 30, the product is .2 * 30 = 6, which is larger than five. So we may use the normal distribution as approximation of the sampling distribution.</p>
<p>Note that this rule of thumb uses one minus the probability, if the probability is larger than .5. In other words, it uses the smaller of two probabilities: the probability that an observation has the characteristic and the probability that it has not. For example, if we want to test the probability of drawing a candy that is not yellow, the probability is .8 and we use 1 - 0.8 = 0.2, which is then multiplied by the sample size.</p>
<p>Apart from the normal distribution, there are several other theoretical probability distributions. We have the <em>binomial distribution</em> for a proportion, the <em>t distribution</em> for one or two sample means, regression coefficients, and correlation coefficients, the <em>F distribution</em> for comparison of variances and comparing means for three or more groups (analysis of variance, ANOVA), and the <em>chi-squared distribution</em> for frequency tables and contingency tables.</p>
<p>For most of these theoretical probability distributions, sample size is important. The larger the sample, the better. There are additional conditions that must be satisfied such as the distribution of the variable in the population. The rules of thumb are summarized in Table @ref(tab:thumb). Bootstrapping and exact tests can be used if conditions for theoretical probability distributions have not been met. Special conditions apply to regression analysis (see Chapter @ref(moderationcat), Section @ref(regr-inference)).</p>
<div class="cell" data-screenshot.opts="{&quot;delay&quot;:2}">
<div class="cell-output-display">

<table class="table" style="font-size: 12px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">Rules of thumb for using theoretical probability distributions.</caption>
 <thead>
  <tr>
   <th style="text-align:left;"> Distribution </th>
   <th style="text-align:left;"> Sample statistic </th>
   <th style="text-align:left;"> Minimum sample size </th>
   <th style="text-align:left;"> Other requirements </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> Binomial distribution </td>
   <td style="text-align:left;"> proportion </td>
   <td style="text-align:left;"> - </td>
   <td style="text-align:left;"> - </td>
  </tr>
  <tr>
   <td style="text-align:left;"> (Standard) normal distribution </td>
   <td style="text-align:left;"> proportion </td>
   <td style="text-align:left;"> times test proportion (&lt;= .5) &gt;= 5 </td>
   <td style="text-align:left;"> - </td>
  </tr>
  <tr>
   <td style="text-align:left;"> (Standard) normal distribution </td>
   <td style="text-align:left;"> one or two means </td>
   <td style="text-align:left;"> &gt; 100 </td>
   <td style="text-align:left;"> OR variable is normally distributed in the population and population standard deviation is known (for each group) </td>
  </tr>
  <tr>
   <td style="text-align:left;"> t distribution </td>
   <td style="text-align:left;"> one or two means </td>
   <td style="text-align:left;"> each group &gt; 30 </td>
   <td style="text-align:left;"> OR variable is normally distributed in each group's population </td>
  </tr>
  <tr>
   <td style="text-align:left;"> t distribution </td>
   <td style="text-align:left;"> (Pearson) correlation coefficient </td>
   <td style="text-align:left;"> - </td>
   <td style="text-align:left;"> variables are normally distributed in the population </td>
  </tr>
  <tr>
   <td style="text-align:left;"> t distribution </td>
   <td style="text-align:left;"> (Spearman) rank correlation coefficient </td>
   <td style="text-align:left;"> &gt; 30 </td>
   <td style="text-align:left;"> - </td>
  </tr>
  <tr>
   <td style="text-align:left;"> t distribution </td>
   <td style="text-align:left;"> regression coefficient </td>
   <td style="text-align:left;"> 20+ per independent variable </td>
   <td style="text-align:left;"> See Chapter 8. </td>
  </tr>
  <tr>
   <td style="text-align:left;"> F distribution </td>
   <td style="text-align:left;"> 3+ means </td>
   <td style="text-align:left;"> all groups are more or less of equal size </td>
   <td style="text-align:left;"> OR all groups have the same population variance </td>
  </tr>
  <tr>
   <td style="text-align:left;"> F distribution </td>
   <td style="text-align:left;"> two variances </td>
   <td style="text-align:left;"> - </td>
   <td style="text-align:left;"> no conditions for Levene's F test </td>
  </tr>
  <tr>
   <td style="text-align:left;"> chi-squared distribution </td>
   <td style="text-align:left;"> row or cell frequencies </td>
   <td style="text-align:left;"> expected frequency &gt;= 1 and 80% &gt;= 5 </td>
   <td style="text-align:left;"> contingency table: 3+ rows or 3+ columns </td>
  </tr>
</tbody>
</table>

</div>
</div>
</section>
<section id="cond-check" class="level3">
<h3 class="anchored" data-anchor-id="cond-check">Checking conditions</h3>
<p>Rules of thumb about sample size are easy to check once we have collected our sample. By contrast, rules of thumb that concern the scores in the population cannot be easily checked, because we do not have information on the population. If we already know what we want to know about the population, why would we draw a sample and do the research in the first place?</p>
<p>We can only use the data in our sample to make an educated guess about the distribution of a variable in the population. For example, if the scores in our sample are clearly normally distributed, it is plausible that the scores in the population are normally distributed.</p>
<p>In this situation, we do not <em>know</em> that the population distribution is normal but we <em>assume</em> it is. If the sample distribution is clearly not normally distributed, we had better not assume that the population is normally distributed. In short, we sometimes have to make assumptions when we decide on using a theoretical probability distribution.</p>
<p>We could use a histogram of the scores in our sample with a normal distribution curve added to evaluate whether a normal distribution applies. Sometimes, we have statistical tests to draw inferences about the population from a sample that we can use to check the conditions. We discuss these tests in a later chapter.</p>
</section>
<section id="complicatedsampling" class="level3">
<h3 class="anchored" data-anchor-id="complicatedsampling">More complicated sample statistics: differences</h3>
<p>Up to this point, we have focused on rather simple sample statistics such as the proportion of yellow candies or the average weight of candies in a sample. Table @ref(tab:thumb), however, contains more complicated sample statistics.</p>
<p>If we compare two groups, for instance, the average weight of yellow and red candies, the sample statistic for which we want to have a sampling distribution must take into account both the average weight of yellow candies and the average weight of red candies. The sample statistic that we are interested in is the difference between the averages of the two samples.</p>
<div class="cell" data-layout-align="center" data-screenshot.opts="{&quot;delay&quot;:5}">
<iframe src="http://82.196.4.233:3838/apps/mean-independent/?showcase=0" width="550px" height="580px" data-external="1">
</iframe>
</div>
<a name="question2.5.6"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="6" type="1">
<li>Click on the button once. Why are these samples called independent? <a href="#answer2.5.6"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.5.7"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="7" type="1">
<li>Click on the button several times. What exactly is the sample statistic in the histogram at the bottom of the app? <a href="#answer2.5.7"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.5.8"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="8" type="1">
<li>Click on the button to draw one thousand samples once or more often. Does the sampling distribution look familiar to you? <a href="#answer2.5.8"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.5.9"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="9" type="1">
<li>What, do you expect, is the mean of the sampling distribution? <a href="#answer2.5.9"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<p>If we draw a sample from both the red and yellow candies in the population, we may calculate the means for both samples and the difference between the two means. For example, the average weight of red candies in the sample bag is 2.76 grams and the average for yellow candies is 2.82 grams. For this pair of samples, the statistic of interest is 2.76 - 2.82 = -0.06, that is, the difference in average weight. If we repeat this many, many times and collect all differences between means in a distribution, we obtain the sampling distribution that we need.</p>
<p>The sampling distribution of the difference between two means is similar to a <em>t</em>-distribution, so we may use the latter to approximate the former. Of course, the conditions for using the <em>t</em> distribution must be met.</p>
<p>It is important to note that we do not create separate sampling distributions for the average weight of yellow candies and for the average weight of red candies and then look at the difference between the two sampling distributions. Instead, we create <em>one sampling distribution for the statistic of interest</em>, namely the difference between means. We cannot combine different sampling distributions into a new sampling distribution. We will see the importance of this when we discuss mediation (Chapter @ref(mediation)).</p>
</section>
<section id="independent-samples" class="level3">
<h3 class="anchored" data-anchor-id="independent-samples">Independent samples</h3>
<p>If we compare two means, there are two fundamentally different situations that are sometimes difficult to distinguish. When comparing the average weight of yellow candies to the average weight of red candies, we are comparing two samples that are <em>statistically independent</em> (see Figure @ref(fig:mean-independent)), which means that we could have drawn the samples separately.</p>
<p>In principle, we could distinguish between a population of yellow candies and a population of red candies, and sample yellow candies from the first population and separately sample red candies from the other population. Whether we sampled the colours separately or not does not matter. The fact that we could have done so implies that the sample of red candies is not affected by the sample of yellow candies or the other way around. The samples are statistically independent.</p>
<p>This is important for the way in which probabilities are calculated. Just think of the simple example of flipping two coins. The probability of having heads twice in a row is .5 times .5, that is .25, if the coins are fair and the result of the second coin does not depend on the result of the first coin. The second flip is not affected by the first flip.</p>
<p>Imagine that a magnetic field is activated if the first coin lands with heads up and that this magnetic field increases the odds that the second coin will also be heads. Now, the second toss is not independent of the first toss and the probability of getting heads twice is larger than .25.</p>
</section>
<section id="dependentsamples" class="level3">
<h3 class="anchored" data-anchor-id="dependentsamples">Dependent samples</h3>
<p>The example of a manipulated second toss is applicable to repeated measurements. If we want to know how quickly the yellow colour fades when yellow candies are exposed to sun light, we may draw a sample of yellow candies once and measure the colourfulness of each candy at least twice: at the start and end of some time interval. We compare the colourfulness of a candy at the second measurement to its colourfulness at the first measurement.</p>
<div class="cell" data-layout-align="center" data-screenshot.opts="{&quot;delay&quot;:5}">
<iframe src="http://82.196.4.233:3838/apps/mean-dependent/?showcase=0" width="560px" height="580px" data-external="1">
</iframe>
</div>
<a name="question2.5.10"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="10" type="1">
<li>In Figure @ref(fig:mean-dependent), use the <strong>Sample 1 case</strong> button repeatedly to draw a sample of five observations. What is the precise meaning of the numbers on the horizontal axis in the dot plot representing the sample (in the middle of Figure @ref(fig:mean-dependent))? <a href="#answer2.5.10"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.5.11"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="11" type="1">
<li>Why is the sample called dependent or paired? <a href="#answer2.5.11"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.5.12"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="12" type="1">
<li>Draw 1,000 samples to obtain a sampling distribution. What is the precise meaning of the numbers on the horizontal axis in the histogram of the sampling distribution? <a href="#answer2.5.12"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<p>In this example, we are comparing two means, just like the yellow versus red candy weight example, but now the samples for both measurements are the same. It is impossible to draw the sample for the second measurement independently from the sample for the first measurement if we want to compare repeated measurements. Here, the second sample is fixed once we have drawn the first sample. The samples are <em>statistically dependent</em>; they are <em>paired samples</em>.</p>
<p>With dependent samples, probabilities have to be calculated in a different way, so we need a special sampling distribution. In the interactive content above, you may have noticed a relatively simple solution for two repeated measurements. We just calculate the difference between the two measurements for each candy in the sample and use the mean of this new difference variable as the sample statistic that we are interested in. The <em>t</em>-distribution, again, offers a good approximation of the sampling distribution of dependent samples if the samples are not too small.</p>
<p>For other applications, the actual sampling distributions can become quite complicated but we do not have to worry about that. If we choose the right technique, our statistical software will take care of this.</p>
</section>
<section id="answers-4" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="answers-4">Answers</h3>
<a name="answer2.5.1"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 1.</p>
<ul>
<li>The curve fits the histogram of observed sample means quite well. Discrepancies are mainly due to the jagged layout of the histogram, which results from binning the data (to create bars) and from the fact that the number of samples is large but not very large.</li>
<li>For the sampling distribution of means we know that the normal or (Student) <em>t</em> distribution represents the sampling distribution very accurately. <a href="#question2.5.1"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.5.2"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 2.</p>
<ul>
<li>The borders demarcating the lowest and highest 2.5% of sample means in the theoretical probability distribution (the dotted lines) nicely coincide with the border between red or green and blue bars in the histogram in most of the sampling distributions that we generate with this app. <a href="#question2.5.2"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.5.3"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 3.</p>
<ul>
<li>The width/peakedness of the sampling distribution changes but the normal curve fits the distribution well. <a href="#question2.5.3"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.5.4"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 4.</p>
<ul>
<li>A larger sample produces a sampling distribution that is more peaked. This means that the sample statistic outcomes are closer to the true population value (which is the mean of the sampling distribution).</li>
<li>In bags containing only two candies, we may often encounter bags without yellow candies (sample proportion of yellow candies: 0.0) or bags with two yellow candies (sample proportion of yellow candies: 1.0). Both values are quite different from the true population proportion (0.5).</li>
<li>In bags containing two-hundred candies, we will hardly ever encounter no yellow candies (0.0) or only yellow candies (1.0) if the proportion of candies in the population is 0.5. In these large bags, the proportion of yellow candies is usually be close to 0.5. The sample proportions are closer to the true population proportion. <a href="#question2.5.4"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.5.5"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 5.</p>
<ul>
<li>The population proportion (parameter value) is equal to the average of the sampling distribution because the sample proportion is an unbiased estimator of the population proportion. So if we change the population proportion, the center of the sampling distribution changes accordingly.</li>
<li>In addition, the sampling distribution becomes less symmetrical/more skewed if the population proportion approaches zero or one. Because proportions cannot be less than zero or more than one, the sampling distribution cannot remain symmetrical if the population proportion is near zero or one. <a href="#question2.5.5"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.5.6"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 6.</p>
<ul>
<li>It is in principle possible to draw a random sample of red candies separately from a random sample of yellow candies. <a href="#question2.5.6"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.5.7"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 7.</p>
<ul>
<li>It is the difference between average weight of red candies and average weight of yellow candies in a sample.</li>
<li>This is illustrated by the equation directly above the graph of the sampling distribution, which subtracts the average weight of yellow candies (in yellow typeface) from the average weight of red candies (in red typeface). The result is added to the sampling distribution. <a href="#question2.5.7"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.5.8"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 8.</p>
<ul>
<li>The sampling distribution has a bell shape like the normal or (Student) <em>t</em> distribution. <a href="#question2.5.8"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.5.9"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 9.</p>
<ul>
<li>The true difference in averages in the population is what we expect as the average difference in the sampling distribution.</li>
<li>Average weight of red candies in the population is 2.8 grams and the average weight in the population of yellow candies is 3.1 grams. The average weight difference in the population is 2.8 - 3.1 = -0.3 grams. This is our expectation.</li>
<li>The centre of the sampling distribution is indeed at -0.3 if we draw thousands of samples. <a href="#question2.5.9"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.5.10"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 10.</p>
<ul>
<li>The numbers on the horizontal axis in the sample histogram represent the difference in colour intensity for each pair of cases that is drawn.</li>
<li>In each draw, one case in the before population (red) and the same case in the after population (orange) is selected. The difference in colour intensity between the before and after measurement is calculated in the equation below the population dot plots. The calculated difference for this pair is represented by a dot in the figure in the middle. <a href="#question2.5.10"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.5.11"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 11.</p>
<ul>
<li>A case appears both in the before and after population: We have a before and after measurement of colour intensity for each case (candy). These two measurements are related or paired because they refer to the same candy.</li>
<li>As a consequence, if we draw candies for our before measurement, we also draw the candies for our after measurement. The after sample depends on the before sample. <a href="#question2.5.11"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

<a name="answer2.5.12"></a> ::: {.cell type=‘rmdanswer’}
<div class="rmdanswer">
<p>Answer to Question 12.</p>
<ul>
<li>The numbers on the horizontal axis in the histogram of the sampling distribution signify the average difference in colour intensity of the candies in a sample (of five candies). <a href="#question2.5.12"><img src="icons/2question.png" width="161px" align="right"></a>
</li></ul></div>
:::

</section>
</section>
<section id="spss-and-theoretical-approximation-of-the-sampling-distribution" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="spss-and-theoretical-approximation-of-the-sampling-distribution"><span class="header-section-number">2.6</span> SPSS and Theoretical Approximation of the Sampling Distribution</h2>
<p>By default, SPSS uses a theoretical probability distribution to approximate the sampling distribution. It chooses the correct theoretical distribution but you yourself should check if the conditions for using this distribution are met. For example, is the sample large enough or is it plausible that the variable is normally distributed in the population?</p>
<p>In one case, SPSS automatically selects an exact approach if the conditions for a theoretical approximation are not met. If you apply a chi-squared test to a contingency table in SPSS, SPSS will automatically apply Fisher’s exact test if the table has two rows and two columns. In all other cases, you have to select bootstrapping or an exact approach yourself if the conditions for a theoretical approximation are not met.</p>
<p>We are not going to practice with theoretical approximations in SPSS, now. Because theoretical approximation is the default approach in SPSS, we will encounter it in the exercises in later chapters.</p>
</section>
<section id="when-do-we-use-which-approach-to-the-sampling-distribution" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="when-do-we-use-which-approach-to-the-sampling-distribution"><span class="header-section-number">2.7</span> When Do We Use Which Approach to the Sampling Distribution?</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/decision.png" class="img-fluid figure-img" width="775"></p>
<p></p><figcaption class="figure-caption">Diagram for selecting the type of sampling distribution.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>By default, SPSS uses a theoretical approximation of the sampling distribution. Select the right test in SPSS and SPSS ensures that an appropriate theoretical probability distribution is used. You, however, must check whether the sample meets the conditions for using this theoretical probability distribution, see Table @ref(tab:thumb).</p>
<p>If the conditions for using a theoretical probability distribution are not met or if we do not have a theoretical approximation to the sampling distribution, we use bootstrapping or an exact approach. We can always use bootstrapping but an exact approach is available only if the variables are categorical. An exact approach is more accurate than bootstrapping and approximation with a theoretical probability distribution, for example, the chi-squared distribution, so we prefer the exact approach over bootstrapping if we are dealing with categorical variables.</p>
</section>
<section id="test-your-understanding" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="test-your-understanding"><span class="header-section-number">2.8</span> Test Your Understanding</h2>
<div class="cell" data-layout-align="center" data-screenshot.opts="{&quot;delay&quot;:5}">
<iframe src="http://82.196.4.233:3838/apps/bootstrapping/?showcase=0" width="775px" height="462px" data-external="1">
</iframe>
</div>
<a name="question2.8.1"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol type="1">
<li>Why does Figure @ref(fig:models-summary1) not show a population? <a href="#answer2.8.1"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.8.2"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="2" type="1">
<li>Which type of bootstrap sampling is better here: with or without replacement? Justify your answer. <a href="#answer2.8.2"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.8.3"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="3" type="1">
<li>Draw a new initial sample in Figure @ref(fig:models-summary1). Is the bootstrapped sampling distribution going to resemble the true sampling distribution? Note that twenty per cent of the candies in the population are yellow. Motivate your answer. Draw 1,000 bootstrap samples to check your answer. <a href="#answer2.8.3"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<div class="cell">
<div class="cell-output-display">

<table class="table" style="font-size: 12px; width: auto !important; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">Number of heads for a toss of three coins.</caption>
 <thead>
  <tr>
   <th style="text-align:left;"> Number of heads </th>
   <th style="text-align:left;"> Combination </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> 0 </td>
   <td style="text-align:left;"> tail-tail-tail </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 1 </td>
   <td style="text-align:left;"> tail-tail-head </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 1 </td>
   <td style="text-align:left;"> tail-head-tail </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 1 </td>
   <td style="text-align:left;"> head-tail-tail </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> head-head-tail </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> head-tail-head </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> tail-head-head </td>
  </tr>
  <tr>
   <td style="text-align:left;"> 3 </td>
   <td style="text-align:left;"> head-head-head </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Total </td>
   <td style="text-align:left;"> 8 </td>
  </tr>
</tbody>
</table>

</div>
</div>
<a name="question2.8.4"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="4" type="1">
<li>Calculate the exact probability distribution of the number of heads in a toss of three fair coins (Table @ref(tab:models-summary-3)). <a href="#answer2.8.4"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.8.5"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="5" type="1">
<li>In which situations can we use exact probabilities as a sampling distribution? <a href="#answer2.8.5"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<div class="cell" data-layout-align="center" data-screenshot.opts="{&quot;delay&quot;:5}">
<iframe src="http://82.196.4.233:3838/apps/normal-approximation/?showcase=0" width="420px" height="300px" data-external="1">
</iframe>
</div>
<a name="question2.8.6"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="6" type="1">
<li>Generate a sampling distribution of average sample candy weight in Figure @ref(fig:models-summary2). Try to explain in your own words why the sampling distribution of a sample mean has a bell shape. <a href="#answer2.8.6"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.8.7"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="7" type="1">
<li>Which part of the graph in Figure @ref(fig:models-summary2) represents the theoretical probability distribution and what is the name of this distribution? <a href="#answer2.8.7"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<a name="question2.8.8"></a> ::: {.cell type=‘rmdquestion’}
<div class="rmdquestion">
<ol start="8" type="1">
<li>Does this theoretical probability distribution always fit the simulated sampling distribution in Figure @ref(fig:models-summary2)? Create several sampling distributions and explain why we pay special attention to the lowest (red) and highest (green) 2.5% of the sample means. <a href="#answer2.8.8"><img src="icons/2answer.png" width="115px" align="right"></a>
</li></ol></div>
:::

<section id="answers-5" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="answers-5">Answers</h3>
<div class="cell" type="rmdanswer">

<div class="rmdanswer">
Answers to the Test Your Understanding questions will be shown in the web book when the last tutor group has discussed this chapter.
</div>
</div>
<p><a name="answer2.8.1"></a> ::: {.cell type=‘rmdanswer’}</p>
<p>:::</p>
<p><a name="answer2.8.2"></a> ::: {.cell type=‘rmdanswer’}</p>
<p>:::</p>
<p><a name="answer2.8.3"></a> ::: {.cell type=‘rmdanswer’}</p>
<p>:::</p>
<p><a name="answer2.8.4"></a> ::: {.cell type=‘rmdanswer’}</p>
<p>:::</p>
<p><a name="answer2.8.5"></a> ::: {.cell type=‘rmdanswer’}</p>
<p>:::</p>
<p><a name="answer2.8.6"></a> ::: {.cell type=‘rmdanswer’}</p>
<p>:::</p>
<p><a name="answer2.8.7"></a> ::: {.cell type=‘rmdanswer’}</p>
<p>:::</p>
<p><a name="answer2.8.8"></a> ::: {.cell type=‘rmdanswer’}</p>
<p>:::</p>
</section>
</section>
<section id="take-home-points" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="take-home-points"><span class="header-section-number">2.9</span> Take-Home Points</h2>
<ul>
<li><p>We may create an exact sampling distribution or simulate a bootstrap sampling distribution in simple situations or if we have a lot of computing power.</p></li>
<li><p>For a bootstrap sampling distribution, we need about 5,000 bootstrap samples from our original sample.</p></li>
<li><p>An exact sampling distribution can only be used with categorical variables.</p></li>
<li><p>We can often approximate the sampling distribution of a sample statistic with a known theoretical probability distribution.</p></li>
<li><p>Approximations only work well under conditions, which we have to check.</p></li>
<li><p>Conditions usually involve the size of the sample, sample type (independent vs.&nbsp;dependent/paired), and the shape or variance of the population distribution.</p></li>
<li><p>If these conditions are not met or we do not have a theoretical approximation to the sampling distribution, we use bootstrapping or exact tests.</p></li>
<li><p>Samples are independent if, in principle, we can draw a sample for one group without taking into account the sample for another group of cases. Otherwise, the samples are dependent or paired. 
<script type="application/shiny-prerendered" data-context="server-start">
# All code chunks that should never be shown must have the echo=FALSE option.
# Chunks with answers to exercises have the echo option not set, so their visibility depends on the the echo option set for all chunks here. Set it to FALSE if the answers are always visible.
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE, eval=TRUE, tidy=TRUE)
# Set output format for kableExtra tables: "html" or "latex"
options(knitr.table.format = "latex")
# Don't show NAs in kable tables.
options(knitr.kable.NA = "")
# Libraries used.
library(tidyverse)
library(knitr)
library(kableExtra)
library(visNetwork)
library(bookdown)
library(haven)
# Basic colors and layout.
source("apps/plottheme/styling.R")
# Chunks with answers to Test Your Understanding questions are set to a boolean variable for each chapter, which can be set to TRUE for showing the answers.
# Show TYU answers per chapter. Change between FALSE and TRUE.
ch1 <- FALSE
ch2 <- FALSE
ch3 <- FALSE
ch4 <- FALSE
ch5 <- FALSE
ch6 <- FALSE
ch7 <- FALSE
ch8 <- FALSE
ch9 <- FALSE
ch10 <- FALSE
ch11 <- FALSE
</script>
 
<script type="application/shiny-prerendered" data-context="server-extras">
ojs_define <- function(..., .session = shiny::getDefaultReactiveDomain()) {
  quos <- rlang::enquos(...)
  vars <- rlang::list2(...)
  nm <- names(vars)
  if (is.null(nm)) {
    nm <- rep_len("", length(vars))
  }
  mapply(function(q, nm, val) {
    # Infer name, if possible
    if (nm == "") {
      tryCatch({
        nm <- rlang::as_name(q)
      }, error = function(e) {
        code <- paste(collapse = "\n", deparse(rlang::f_rhs(q)))
        stop("ojs_define() could not create a name for the argument: ", code)
      })
    }
    .session$output[[nm]] <- val
    outputOptions(.session$output, nm, suspendWhenHidden = FALSE)
    .session$sendCustomMessage("ojs-export", list(name = nm))
    NULL
  }, quos, nm, vars, SIMPLIFY = FALSE, USE.NAMES = FALSE)
  invisible()
}
</script>
</p></li>
</ul>
<!--html_preserve-->

<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["kePrint"]},{"type":"character","attributes":{},"value":["0.0.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["kePrint-0.0.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["kePrint.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["kableExtra"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.3.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["lightable"]},{"type":"character","attributes":{},"value":["0.0.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lightable-0.0.1"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["lightable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["kableExtra"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.3.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["kePrint"]},{"type":"character","attributes":{},"value":["0.0.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["kePrint-0.0.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["kePrint.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["kableExtra"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.3.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["lightable"]},{"type":"character","attributes":{},"value":["0.0.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lightable-0.0.1"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["lightable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["kableExtra"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.3.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["kePrint"]},{"type":"character","attributes":{},"value":["0.0.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["kePrint-0.0.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["kePrint.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["kableExtra"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.3.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["lightable"]},{"type":"character","attributes":{},"value":["0.0.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lightable-0.0.1"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["lightable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["kableExtra"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["1.3.4"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->

<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87]}},"value":[{"type":"character","attributes":{},"value":["assertthat","backports","base","bookdown","broom","cellranger","cli","colorspace","compiler","crayon","datasets","DBI","dbplyr","digest","dplyr","ellipsis","evaluate","fansi","fastmap","forcats","fs","gargle","generics","ggplot2","glue","googledrive","googlesheets4","graphics","grDevices","grid","gtable","haven","highr","hms","htmltools","htmlwidgets","httpuv","httr","jsonlite","kableExtra","knitr","later","lifecycle","lubridate","magrittr","methods","mime","modelr","munsell","pillar","pkgconfig","promises","purrr","R6","RColorBrewer","Rcpp","readr","readxl","reprex","rlang","rmarkdown","rstudioapi","rvest","scales","shiny","stats","stringi","stringr","svglite","systemfonts","tibble","tidyr","tidyselect","tidyverse","tools","tzdb","utf8","utils","vctrs","viridisLite","visNetwork","webshot","withr","xfun","xml2","xtable","yaml"]},{"type":"character","attributes":{},"value":["0.2.1","1.4.1","4.2.3","0.31","1.0.1","1.1.0","3.4.1","2.0-3","4.2.3","1.5.2","4.2.3","1.1.3","2.2.1","0.6.30","1.0.10","0.3.2","0.17","1.0.3","1.1.0","0.5.2","1.5.2","1.2.1","0.1.3","3.3.6","1.6.2","2.0.0","1.0.1","4.2.3","4.2.3","4.2.3","0.3.1","2.5.1","0.9","1.1.2","0.5.3","1.5.4","1.6.6","1.4.4","1.8.2","1.3.4","1.40","1.3.0","1.0.3","1.8.0","2.0.3","4.2.3","0.12","0.1.9","0.5.0","1.8.1","2.0.3","1.2.0.1","0.3.5","2.5.1","1.1-3","1.0.9","2.1.3","1.4.1","2.0.2","1.0.6","2.17","0.14","1.0.3","1.2.1","1.7.3","4.2.3","1.7.8","1.4.1","2.1.0","1.0.4","3.1.8","1.2.1","1.2.0","1.3.2","4.2.3","0.3.0","1.2.2","4.2.3","0.4.2","0.4.1","2.1.2","0.5.4","2.5.0","0.35","1.3.3","1.8-4","2.3.6"]}]}]}
</script>
<!--/html_preserve-->


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./01-samplingdistr.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Sampling Distribution: How Different Could My Sample Have Been?</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./summary.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Summary</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>